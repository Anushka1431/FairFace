{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-09T05:48:30.737565Z",
     "iopub.status.busy": "2025-04-09T05:48:30.737294Z",
     "iopub.status.idle": "2025-04-09T05:51:52.699538Z",
     "shell.execute_reply": "2025-04-09T05:51:52.698456Z",
     "shell.execute_reply.started": "2025-04-09T05:48:30.737544Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y pillow\n",
    "!pip install pillow==10.2.0 \n",
    "!pip install torch torchvision opencv-python-headless\n",
    "!pip install numpy pandas matplotlib seaborn\n",
    "!pip install facenet-pytorch \n",
    "#after this restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:00:38.267746Z",
     "iopub.status.busy": "2025-04-09T06:00:38.267193Z",
     "iopub.status.idle": "2025-04-09T06:00:38.272375Z",
     "shell.execute_reply": "2025-04-09T06:00:38.271440Z",
     "shell.execute_reply.started": "2025-04-09T06:00:38.267716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Replace 'dataset_folder' with the actual folder name\n",
    "dir_path = \"/kaggle/working/FairFace_Subset\"\n",
    "\n",
    "shutil.rmtree(dir_path, ignore_errors=True)\n",
    "\n",
    "print(f\"Deleted directory: {dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:01:28.057978Z",
     "iopub.status.busy": "2025-04-09T06:01:28.057609Z",
     "iopub.status.idle": "2025-04-09T06:01:32.467107Z",
     "shell.execute_reply": "2025-04-09T06:01:32.466402Z",
     "shell.execute_reply.started": "2025-04-09T06:01:28.057939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load FairFace dataset from Hugging Face\n",
    "dataset = load_dataset('HuggingFaceM4/FairFace', '0.25')\n",
    "\n",
    "# Define dataset sizes\n",
    "train_data = dataset['train']  # Full training set\n",
    "val_data = dataset['validation']  # Full validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:01:35.874491Z",
     "iopub.status.busy": "2025-04-09T06:01:35.874202Z",
     "iopub.status.idle": "2025-04-09T06:01:35.878905Z",
     "shell.execute_reply": "2025-04-09T06:01:35.878018Z",
     "shell.execute_reply.started": "2025-04-09T06:01:35.874470Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define storage paths in Kaggle\n",
    "BASE_PATH = \"/kaggle/working/FairFace_Subset\"\n",
    "train_path = os.path.join(BASE_PATH, \"train\")\n",
    "val_path = os.path.join(BASE_PATH, \"val\")\n",
    "#test_path = os.path.join(BASE_PATH, \"test\")\n",
    "\n",
    "# Create directories\n",
    "for path in [train_path, val_path]:\n",
    "    os.makedirs(path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-09T06:01:21.645825Z",
     "iopub.status.busy": "2025-04-09T06:01:21.645517Z",
     "iopub.status.idle": "2025-04-09T06:01:21.663515Z",
     "shell.execute_reply": "2025-04-09T06:01:21.662466Z",
     "shell.execute_reply.started": "2025-04-09T06:01:21.645802Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 160  # FaceNet input size\n",
    "\n",
    "# Function to preprocess & save images + metadata\n",
    "def preprocess_and_save(data, folder, csv_filename):\n",
    "    metadata = []\n",
    "    for i, sample in enumerate(data):\n",
    "        img = sample[\"image\"]\n",
    "        img = img.convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
    "        img_filename = f\"{i}.jpg\"\n",
    "        img_path = os.path.join(folder, img_filename)\n",
    "        img.save(img_path)\n",
    "\n",
    "        metadata.append({\n",
    "            \"image_path\": img_path,\n",
    "            \"age\": sample[\"age\"],\n",
    "            \"gender\": sample[\"gender\"],\n",
    "            \"race\": sample[\"race\"]\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(metadata)\n",
    "    df.to_csv(os.path.join(BASE_PATH, csv_filename), index=False)\n",
    "\n",
    "# Save train, val, test sets\n",
    "preprocess_and_save(train_data, train_path, \"train.csv\")\n",
    "preprocess_and_save(val_data, val_path, \"val.csv\")\n",
    "#preprocess_and_save(test_data, test_path, \"test.csv\")\n",
    "\n",
    "print(\"Preprocessed Images & Metadata Saved in Kaggle Working Directory!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:01:41.276198Z",
     "iopub.status.busy": "2025-04-09T06:01:41.275696Z",
     "iopub.status.idle": "2025-04-09T06:01:41.528033Z",
     "shell.execute_reply": "2025-04-09T06:01:41.527143Z",
     "shell.execute_reply.started": "2025-04-09T06:01:41.276154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata_path = os.path.join(BASE_PATH, \"train.csv\")\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Display a random image\n",
    "sample_idx = 20\n",
    "sample_data = df.iloc[sample_idx]\n",
    "image_path = sample_data[\"image_path\"]\n",
    "image = Image.open(image_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Age: {sample_data['age']}, Gender: {sample_data['gender']}, Race: {sample_data['race']}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Metadata:\", sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:56:04.279044Z",
     "iopub.status.busy": "2025-04-09T05:56:04.278703Z",
     "iopub.status.idle": "2025-04-09T05:56:04.386293Z",
     "shell.execute_reply": "2025-04-09T05:56:04.385478Z",
     "shell.execute_reply.started": "2025-04-09T05:56:04.279014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join(BASE_PATH, \"train.csv\"))\n",
    "print(df.head())  # Check if \"race\" column exists and has valid values\n",
    "print(df[\"race\"].unique())  # See all race categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:01:59.640722Z",
     "iopub.status.busy": "2025-04-09T06:01:59.640373Z",
     "iopub.status.idle": "2025-04-09T06:01:59.645288Z",
     "shell.execute_reply": "2025-04-09T06:01:59.644219Z",
     "shell.execute_reply.started": "2025-04-09T06:01:59.640673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 86744\n",
      "Validation set size: 10954\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "from PIL import Image\n",
    "\n",
    "# Load Dataset\n",
    "BASE_PATH = \"/kaggle/working/FairFace_Subset\"  # Change path if needed\n",
    "csv_path = os.path.join(BASE_PATH, \"train.csv\")  # Modify for test/val as needed\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\033[1;34m Sample Dataset Preview: \\033[0m\")\n",
    "print(tabulate(df.head(), headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# Dataset Summary Table\n",
    "summary_table = df.describe(include=\"all\").transpose()\n",
    "summary_table = summary_table[[\"count\", \"unique\", \"top\", \"freq\"]].reset_index()\n",
    "summary_table.columns = [\"Feature\", \"Total Samples\", \"Unique Values\", \"Most Frequent Value\", \"Frequency\"]\n",
    "\n",
    "# Print summary table in a nice format\n",
    "print(\"\\n\\033[1;32m Dataset Description: \\033[0m\")\n",
    "print(tabulate(summary_table, headers=\"keys\", tablefmt=\"fancy_grid\", stralign=\"center\"))\n",
    "\n",
    "# Visualizing Class Distributions\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.countplot(x=\"race\", data=df, palette=\"coolwarm\", order=df[\"race\"].value_counts().index)\n",
    "plt.title(\"Race Distribution in FairFace Dataset\", fontsize=14)\n",
    "plt.xlabel(\"Race Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Display Sample Images from Each Race\n",
    "def display_sample_images(df, num_samples=5):\n",
    "    unique_races = df[\"race\"].unique()\n",
    "    fig, axes = plt.subplots(len(unique_races), num_samples, figsize=(15, len(unique_races) * 2))\n",
    "    \n",
    "    for i, race in enumerate(unique_races):\n",
    "        race_samples = df[df[\"race\"] == race].sample(num_samples, random_state=42)\n",
    "        for j, img_path in enumerate(race_samples[\"image_path\"]):\n",
    "            img = Image.open(img_path)\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis(\"off\")\n",
    "            if j == 0:\n",
    "                axes[i, j].set_title(race, fontsize=12, fontweight=\"bold\")\n",
    "    \n",
    "    plt.suptitle(\"Sample Images from Each Race Category\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call function to display images\n",
    "display_sample_images(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:02:05.702608Z",
     "iopub.status.busy": "2025-04-09T06:02:05.702274Z",
     "iopub.status.idle": "2025-04-09T06:02:05.872100Z",
     "shell.execute_reply": "2025-04-09T06:02:05.871226Z",
     "shell.execute_reply.started": "2025-04-09T06:02:05.702572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "def lighten_image(img, factor=1.8):  # Increase brightness by 20%\n",
    "    return TF.adjust_brightness(img, factor)\n",
    "\n",
    "# Image Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    #transforms.Lambda(lambda img: lighten_image(img, factor=1.2)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "class FairFaceDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Print unique race labels for debugging\n",
    "        print(\"Unique race labels in dataset:\", self.data[\"race\"].unique())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx][\"image_path\"]\n",
    "        race_label = str(self.data.iloc[idx][\"race\"]).strip().title()  # Normalize race name\n",
    "\n",
    "        # Ensure label exists in race_classes, otherwise use -1\n",
    "        # label = race_classes.get(race_label, -1)\n",
    "        label = int(self.data.iloc[idx][\"race\"])\n",
    "        # Debugging: Print race label if it's missing\n",
    "        if label == -1:\n",
    "            print(f\"Warning: Unrecognized race label '{race_label}' at index {idx}\")\n",
    "\n",
    "        # Check if image file exists\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image not found at {img_path}. Using placeholder.\")\n",
    "            img = Image.new(\"RGB\", (160, 160))  # Create a blank image\n",
    "        else:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "        if label == 4:  \n",
    "            img = lighten_image(img, factor=1.8)  # Make lighter\n",
    "          \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Base Path\n",
    "BASE_PATH = \"/kaggle/working/FairFace_Subset\"  # Change this to your actual dataset path\n",
    "\n",
    "# Load Datasets with Transforms\n",
    "train_dataset = FairFaceDataset(os.path.join(BASE_PATH, \"train.csv\"), transform=transform)\n",
    "val_dataset = FairFaceDataset(os.path.join(BASE_PATH, \"val.csv\"), transform=transform)\n",
    "#test_dataset = FairFaceDataset(os.path.join(BASE_PATH, \"test.csv\"), transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "#test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Data Loaders Created Successfully!\")\n",
    "\n",
    "# Debugging: Check first batch\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    print(f\"Label batch shape: {labels.shape}\")\n",
    "    print(f\"First 5 labels: {labels[:5].tolist()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:02:11.313369Z",
     "iopub.status.busy": "2025-04-09T06:02:11.313065Z",
     "iopub.status.idle": "2025-04-09T06:02:11.993970Z",
     "shell.execute_reply": "2025-04-09T06:02:11.993080Z",
     "shell.execute_reply.started": "2025-04-09T06:02:11.313347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom FaceNet Classifier \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "facenet = InceptionResnetV1(pretrained=\"vggface2\").eval().to(device)\n",
    "\n",
    "# Custom Model\n",
    "class FaceNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(FaceNetClassifier, self).__init__()\n",
    "        self.facenet = facenet\n",
    "        # self.fc = nn.Linear(512, num_classes)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.facenet(x)  # No torch.no_grad(), so it's trainable\n",
    "        return self.classifier(x)\n",
    "for param in facenet.parameters():\n",
    "    param.requires_grad = True  # Unfreeze all layers\n",
    "\n",
    "# Initialize Model\n",
    "model = FaceNetClassifier(num_classes=7).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Optimizer & Learning Rate Scheduler\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "#optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T19:07:31.366979Z",
     "iopub.status.busy": "2025-04-06T19:07:31.366575Z",
     "iopub.status.idle": "2025-04-06T19:07:32.080773Z",
     "shell.execute_reply": "2025-04-06T19:07:32.079867Z",
     "shell.execute_reply.started": "2025-04-06T19:07:31.366941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom ResNet-50 Classifier\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(ResNet50Classifier, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze early layers if needed\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = True  # Set False to freeze\n",
    "\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Initialize model\n",
    "model = ResNet50Classifier(num_classes=7).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-09T06:02:26.508816Z",
     "iopub.status.busy": "2025-04-09T06:02:26.508491Z",
     "iopub.status.idle": "2025-04-09T06:05:49.686051Z",
     "shell.execute_reply": "2025-04-09T06:05:49.685149Z",
     "shell.execute_reply.started": "2025-04-09T06:02:26.508792Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 400\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    print(f\"\\n🚀 Starting Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        print(f\" Processing Batch {batch_idx+1}/{len(train_loader)}\")\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        print(f\"🔹 Batch {batch_idx+1} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if batch_idx == 2:\n",
    "            break\n",
    "    \n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"✅ Epoch {epoch+1}/{EPOCHS} | Loss: {running_loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:08:16.752481Z",
     "iopub.status.busy": "2025-04-09T06:08:16.752144Z",
     "iopub.status.idle": "2025-04-09T06:08:41.049153Z",
     "shell.execute_reply": "2025-04-09T06:08:41.048213Z",
     "shell.execute_reply.started": "2025-04-09T06:08:16.752455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_dataset.data['race'].unique(),\n",
    "            yticklabels=train_dataset.data['race'].unique())\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:07:25.754749Z",
     "iopub.status.busy": "2025-04-09T06:07:25.754437Z",
     "iopub.status.idle": "2025-04-09T06:07:50.220570Z",
     "shell.execute_reply": "2025-04-09T06:07:50.219767Z",
     "shell.execute_reply.started": "2025-04-09T06:07:25.754725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, roc_auc_score, roc_curve, classification_report, \n",
    "                             matthews_corrcoef)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "all_preds, all_labels, all_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)  # Get probabilities\n",
    "        _, preds = torch.max(outputs, 1)  # Get predicted class\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())  # Store probabilities for ROC-AUC\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "n_classes = cm.shape[0]\n",
    "\n",
    "# Compute per-class metrics\n",
    "TP = np.diag(cm)\n",
    "FN = cm.sum(axis=1) - TP\n",
    "FP = cm.sum(axis=0) - TP\n",
    "TN = cm.sum() - (TP + FN + FP)\n",
    "\n",
    "# Metrics per class\n",
    "accuracy_per_class = TP / cm.sum(axis=1)  \n",
    "precision_per_class = TP / (TP + FP + 1e-6)  \n",
    "recall_per_class = TP / (TP + FN + 1e-6)\n",
    "f1_per_class = 2 * (precision_per_class * recall_per_class) / (precision_per_class + recall_per_class + 1e-6)\n",
    "specificity_per_class = TN / (TN + FP + 1e-6)\n",
    "FPR_per_class = FP / (FP + TN + 1e-6)\n",
    "FNR_per_class = FN / (FN + TP + 1e-6)\n",
    "FDR_per_class = FP / (FP + TP + 1e-6)\n",
    "\n",
    "# Matthews Correlation Coefficient (Overall)\n",
    "mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "# Compute ROC-AUC per class\n",
    "auc_scores = []\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve((all_labels == i).astype(int), all_probs[:, i])\n",
    "    auc = roc_auc_score((all_labels == i).astype(int), all_probs[:, i])\n",
    "    auc_scores.append(auc)\n",
    "    \n",
    "    plt.plot(fpr, tpr, label=f'Class {i} (AUC={auc:.2f})')\n",
    "\n",
    "# ROC Curve Plot\n",
    "plt.plot([0,1], [0,1], 'k--')  \n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Prepare table data\n",
    "table_data = []\n",
    "for i in range(n_classes):\n",
    "    table_data.append([\n",
    "        i,\n",
    "        f\"{accuracy_per_class[i]:.4f}\",\n",
    "        f\"{precision_per_class[i]:.4f}\",\n",
    "        f\"{recall_per_class[i]:.4f}\",\n",
    "        f\"{f1_per_class[i]:.4f}\",\n",
    "        f\"{specificity_per_class[i]:.4f}\",\n",
    "        f\"{FPR_per_class[i]:.4f}\",\n",
    "        f\"{FNR_per_class[i]:.4f}\",\n",
    "        f\"{FDR_per_class[i]:.4f}\",\n",
    "        f\"{auc_scores[i]:.4f}\"\n",
    "    ])\n",
    "\n",
    "# Print the table using tabulate\n",
    "headers = [\"Class\", \"Accuracy\", \"Precision\", \"Recall\", \"F1Score\", \"Specificity\", \"FPR\", \"FNR\", \"FDR\"]\n",
    "print(\"\\n\\033[1;34m Class-wise Metrics Table \\033[0m\")  # Blue title\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"fancy_grid\", stralign=\"center\"))\n",
    "\n",
    "# Print overall MCC\n",
    "print(f\"\\n\\033[1;32mMatthews Correlation Coefficient (MCC): {mcc:.4f}\\033[0m\")  # Green MCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T06:19:24.001802Z",
     "iopub.status.busy": "2025-04-09T06:19:24.001454Z",
     "iopub.status.idle": "2025-04-09T06:19:24.390331Z",
     "shell.execute_reply": "2025-04-09T06:19:24.389381Z",
     "shell.execute_reply.started": "2025-04-09T06:19:24.001775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optional: Map class index to race labels (adjust this as per your class mappings)\n",
    "race_labels = {\n",
    "    0: \"White\" , 1: \"Latino_Hispanic\", 2: \"Indian\", 3: \"East Asian\" ,\n",
    "    4: \"Black\", 5:\"Southeast Asian\" , 6: \"Middle Eastern\"\n",
    "}\n",
    "# # Race Mapping\n",
    "# race_classes = {\n",
    "#     'East Asian': 3, 'Indian': 2, 'Black': 4, 'White': 0, 'Middle Eastern': 6, 'Latino_Hispanic': 1,\n",
    "#     'Southeast Asian': 5\n",
    "# }\n",
    "\n",
    "# Plot per-class metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Race\": [race_labels[i] for i in range(n_classes)],\n",
    "    \"Accuracy\": accuracy_per_class,\n",
    "    \"Precision\": precision_per_class,\n",
    "    \"Recall\": recall_per_class,\n",
    "    \"F1 Score\": f1_per_class,\n",
    "    \n",
    "})\n",
    "\n",
    "# Plot all metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics_df.set_index(\"Race\").plot(kind=\"bar\", figsize=(14, 6))\n",
    "plt.title(\"Performance Metrics per Race\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T18:32:43.341438Z",
     "iopub.status.busy": "2025-04-06T18:32:43.341045Z",
     "iopub.status.idle": "2025-04-06T18:32:43.548484Z",
     "shell.execute_reply": "2025-04-06T18:32:43.547717Z",
     "shell.execute_reply.started": "2025-04-06T18:32:43.341408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/working/facenet_race_classifier.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved at {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
